{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Index\n",
      "[10, {215: [2081], 539: [66], 591: [879], 616: [462, 473], 680: [135], 691: [2081], 714: [4], 809: [333], 979: [0]}]\n",
      "Filename, [Positions]\n",
      "20_newsgroups/comp.graphics/38376 [2081]\n",
      "20_newsgroups/comp.graphics/38701 [66]\n",
      "20_newsgroups/comp.graphics/38753 [879]\n",
      "20_newsgroups/comp.graphics/38778 [462, 473]\n",
      "20_newsgroups/comp.graphics/38842 [135]\n",
      "20_newsgroups/comp.graphics/38853 [2081]\n",
      "20_newsgroups/comp.graphics/38876 [4]\n",
      "20_newsgroups/comp.graphics/38971 [333]\n",
      "20_newsgroups/comp.graphics/39663 [0]\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from natsort import natsorted\n",
    "import string\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, 'r', encoding =\"ascii\", errors =\"surrogateescape\") as f:\n",
    "        stuff = f.read()\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    # Remove header and footer.\n",
    "    stuff = remove_header_footer(stuff)\n",
    "    \n",
    "    return stuff\n",
    "\n",
    "def remove_header_footer(final_string):\n",
    "    new_final_string = \"\"\n",
    "    tokens = final_string.split('\\n\\n')\n",
    "\n",
    "    # Remove tokens[0] and tokens[-1]\n",
    "    for token in tokens[1:-1]:\n",
    "        new_final_string += token+\" \"\n",
    "    return new_final_string\n",
    "\n",
    "def preprocessing(final_string):\n",
    "        # Tokenize.\n",
    "    tokenizer = TweetTokenizer()\n",
    "    token_list = tokenizer.tokenize(final_string)\n",
    "\n",
    "    # Remove punctuations.\n",
    "    table = str.maketrans('', '', '\\t')\n",
    "    token_list = [word.translate(table) for word in token_list]\n",
    "    punctuations = (string.punctuation).replace(\"'\", \"\")\n",
    "    trans_table = str.maketrans('', '', punctuations)\n",
    "    stripped_words = [word.translate(trans_table) for word in token_list]\n",
    "    token_list = [str for str in stripped_words if str]\n",
    "\n",
    "    # Change to lowercase.\n",
    "    token_list =[word.lower() for word in token_list]\n",
    "    return token_list\n",
    "\n",
    "# In this example, we create the positional index for only 1 folder.\n",
    "folder_names = [\"comp.graphics\"]\n",
    "\n",
    "# Initialize the stemmer.\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize the file no.\n",
    "fileno = 0\n",
    "\n",
    "# Initialize the dictionary.\n",
    "pos_index = {}\n",
    "\n",
    "# Initialize the file mapping (fileno -> file name).\n",
    "file_map = {}\n",
    "\n",
    "for folder_name in folder_names:\n",
    "\n",
    "    # Open files.\n",
    "    file_names = natsorted(os.listdir(\"20_newsgroups/\" + folder_name))\n",
    "\n",
    "    # For every file.\n",
    "    for file_name in file_names:\n",
    "\n",
    "        # Read file contents.\n",
    "        stuff = read_file(\"20_newsgroups/\" + folder_name + \"/\" + file_name)\n",
    "        \n",
    "        # This is the list of words in order of the text.\n",
    "        # We need to preserve the order because we require positions.\n",
    "        # 'preprocessing' function does some basic punctuation removal,\n",
    "        # stopword removal etc.\n",
    "        final_token_list = preprocessing(stuff)\n",
    "\n",
    "        # For position and term in the tokens.\n",
    "        for pos, term in enumerate(final_token_list):\n",
    "        \n",
    "                    # First stem the term.\n",
    "                    term = stemmer.stem(term)\n",
    "\n",
    "                    # If term already exists in the positional index dictionary.\n",
    "                    if term in pos_index:\n",
    "                        \n",
    "                        # Increment total freq by 1.\n",
    "                        pos_index[term][0] = pos_index[term][0] + 1\n",
    "    \n",
    "                        # Check if the term has existed in that DocID before.\n",
    "                        if fileno in pos_index[term][1]:\n",
    "                            pos_index[term][1][fileno].append(pos)\n",
    "\n",
    "                        else:\n",
    "                            pos_index[term][1][fileno] = [pos]\n",
    "\n",
    "                    # If term does not exist in the positional index dictionary\n",
    "                    # (first encounter).\n",
    "                    else:\n",
    "\n",
    "                        # Initialize the list.\n",
    "                        pos_index[term] = []\n",
    "                        # The total frequency is 1.\n",
    "                        pos_index[term].append(1)\n",
    "                        # The postings list is initially empty.\n",
    "                        pos_index[term].append({})\t\n",
    "                        # Add doc ID to postings list.\n",
    "                        pos_index[term][1][fileno] = [pos]\n",
    "\n",
    "        # Map the file no. to the file name.\n",
    "        file_map[fileno] = \"20_newsgroups/\" + folder_name + \"/\" + file_name\n",
    "\n",
    "        # Increment the file no. counter for document ID mapping\n",
    "        fileno += 1\n",
    "\n",
    "# Sample positional index to test the code.\n",
    "sample_pos_idx = pos_index[\"andrew\"]\n",
    "print(\"Positional Index\")\n",
    "print(sample_pos_idx)\n",
    "\n",
    "file_list = sample_pos_idx[1]\n",
    "print(\"Filename, [Positions]\")\n",
    "for fileno, positions in file_list.items():\n",
    "    print(file_map[fileno], positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
